{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mivpc3rpL1Vk"
   },
   "source": [
    "# 1. Instalação das Dependências\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "q61q81tlgKzV",
    "outputId": "c0fc740d-e7e1-4447-c068-d52f30d7ff2e"
   },
   "outputs": [],
   "source": [
    "!pip install opencv-python tensorflow matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "pNrP0B3ZGatX",
    "outputId": "4ce4de3c-4cdb-445c-84a2-fb4aef99a24c"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Javascript\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "\n",
    "def take_photo(filename='capture.jpg', quality=0.8):\n",
    "    js = Javascript('''\n",
    "      async function takePhoto(quality) {\n",
    "        const div = document.createElement('div');\n",
    "        const capture = document.createElement('button');\n",
    "        capture.textContent = 'Tirar Foto';\n",
    "        div.appendChild(capture);\n",
    "        const video = document.createElement('video');\n",
    "        video.style.display = 'block';\n",
    "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "        document.body.appendChild(div);\n",
    "        div.appendChild(video);\n",
    "        video.srcObject = stream;\n",
    "        await video.play();\n",
    "        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
    "        await new Promise((resolve) => capture.onclick = resolve);\n",
    "        const canvas = document.createElement('canvas');\n",
    "        canvas.width = video.videoWidth;\n",
    "        canvas.height = video.videoHeight;\n",
    "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "        stream.getVideoTracks()[0].stop();\n",
    "        div.remove();\n",
    "        return canvas.toDataURL('image/jpeg', quality);\n",
    "      }\n",
    "      ''')\n",
    "    display(js)\n",
    "    data = eval_js('takePhoto({})'.format(quality))\n",
    "    binary = b64decode(data.split(',')[1])\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(binary)\n",
    "    return filename\n",
    "\n",
    "# Captura a foto\n",
    "photo_filename = take_photo()\n",
    "print(\"Foto salva em:\", photo_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFjFtY4jL_jK"
   },
   "source": [
    "# 2. Preparação e Upload do Dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "-LH2bUr2kNd6",
    "outputId": "9f17582f-5bbe-43a6-e3e0-4cec4c6aba1c"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Carrega o classificador Haar Cascade\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Carrega a imagem capturada\n",
    "img = cv2.imread('capture.jpg')\n",
    "if img is None:\n",
    "    raise ValueError(\"Imagem não encontrada.\")\n",
    "\n",
    "# Converte para escala de cinza\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detecta as faces\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "print(\"Faces detectadas:\", len(faces))\n",
    "\n",
    "# Vamos armazenar as regiões de face para classificar depois\n",
    "face_regions = []\n",
    "for (x, y, w, h) in faces:\n",
    "    face_img = img[y:y+h, x:x+w]  # recorta a face\n",
    "    face_regions.append(((x, y, w, h), face_img))\n",
    "\n",
    "# Exibe a imagem original com as caixas (sem classificação ainda)\n",
    "for (x, y, w, h), _ in face_regions:\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UvqjIiLfClDP"
   },
   "source": [
    "# Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cG8LxVVbCj_T",
    "outputId": "a24c2461-d8f2-4412-a1d2-63cc1c692d82"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Diretório base onde estão as imagens\n",
    "base_dir = \"/content/dataset\"\n",
    "classes = [\"tadeu\", \"marina\"]\n",
    "\n",
    "# Definição do tamanho padrão\n",
    "img_size = (224, 224)\n",
    "\n",
    "# Processa as imagens para garantir tamanho e qualidade uniformes\n",
    "for class_name in classes:\n",
    "    class_dir = os.path.join(base_dir, class_name)\n",
    "\n",
    "    for filename in os.listdir(class_dir):\n",
    "        if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            file_path = os.path.join(class_dir, filename)\n",
    "\n",
    "            # Carrega a imagem\n",
    "            img = Image.open(file_path)\n",
    "\n",
    "            # Converte para RGB (caso tenha transparência ou seja preto e branco)\n",
    "            img = img.convert(\"RGB\")\n",
    "\n",
    "            # Redimensiona para o tamanho padrão\n",
    "            img = img.resize(img_size, Image.LANCZOS)  # Substituindo ANTIALIAS por LANCZOS\n",
    "\n",
    "            # Salva a imagem processada (sobrescrevendo a original)\n",
    "            img.save(file_path, quality=95)\n",
    "\n",
    "            print(f\"Processado: {file_path}\")\n",
    "\n",
    "print(\"Todas as imagens foram pré-processadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sL5xEMZdMB_J"
   },
   "source": [
    "# 3. Data Augmentation nas Imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hO1mbn0CJuKH",
    "outputId": "1e207ff8-870a-45cb-e513-dde40ad5be4a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "\n",
    "# Parâmetros de data augmentation com ruído\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,  # Variação de ângulo\n",
    "    width_shift_range=0.1,  # Pequeno deslocamento horizontal\n",
    "    height_shift_range=0.1,  # Pequeno deslocamento vertical\n",
    "    shear_range=0.1,  # Pequeno cisalhamento\n",
    "    zoom_range=0.1,  # Pequeno zoom\n",
    "    brightness_range=[0.7, 1.3],  # Variação na iluminação\n",
    "    horizontal_flip=True,  # Espelhamento horizontal\n",
    "    fill_mode='nearest',  # Preenchimento suave\n",
    "    preprocessing_function=lambda img: np.clip(img + np.random.normal(loc=0.0, scale=0.02, size=img.shape), 0, 255)  # Adiciona ruído gaussiano\n",
    ")\n",
    "\n",
    "# Diretório base onde estão as imagens originais\n",
    "base_dir = \"/content/dataset\"\n",
    "\n",
    "# Classes a serem processadas\n",
    "classes = [\"tadeu\", \"marina\"]\n",
    "\n",
    "# Número de imagens aumentadas a serem geradas por imagem original\n",
    "num_augmented = 7\n",
    "\n",
    "for class_name in classes:\n",
    "    class_dir = os.path.join(base_dir, class_name)\n",
    "\n",
    "    # Processa cada imagem no diretório da classe\n",
    "    for filename in os.listdir(class_dir):\n",
    "        if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")) and not filename.startswith(\"aug\"):\n",
    "            img_path = os.path.join(class_dir, filename)\n",
    "            img = load_img(img_path)\n",
    "            x = img_to_array(img)\n",
    "            x = x.reshape((1,) + x.shape)\n",
    "\n",
    "            i = 0\n",
    "            # Gera imagens aumentadas e salva no mesmo diretório da imagem original\n",
    "            for batch in datagen.flow(x, batch_size=1, save_to_dir=class_dir, save_prefix='aug', save_format='jpg'):\n",
    "                i += 1\n",
    "                if i >= num_augmented:\n",
    "                    break\n",
    "\n",
    "# Exibir a contagem de imagens por classe após o aumento\n",
    "def count_images():\n",
    "    for class_name in classes:\n",
    "        class_dir = os.path.join(base_dir, class_name)\n",
    "        num_images = len([f for f in os.listdir(class_dir) if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))])\n",
    "        print(f\"Classe {class_name}: {num_images} imagens\")\n",
    "\n",
    "count_images()\n",
    "\n",
    "print(\"Data augmentation finalizado. Imagens aumentadas salvas no mesmo diretório.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUS3EDPWMG3P"
   },
   "source": [
    "# 4. Treinamento do Modelo de Reconhecimento Facial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "n5mrGNYRI_XE",
    "outputId": "baad93d3-7f93-4daa-981b-52a3ffafeb5f"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "# Diretório base onde estão as imagens originais\n",
    "base_dir = \"/content/dataset\"\n",
    "\n",
    "# Definir classes manualmente na ordem correta\n",
    "classes = [\"tadeu\", \"marina\"]\n",
    "# Criando geradores de treino e validação sem data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    validation_split=0.2  # 20% para validação\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    classes=classes,  # Definindo a ordem correta\n",
    "    shuffle=True  # Mantém os dados embaralhados para melhor generalização\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    classes=classes,  # Definindo a ordem correta\n",
    "    shuffle=False  # Validação não precisa ser embaralhada\n",
    ")\n",
    "\n",
    "print(\"Classes detectadas pelo train_generator:\", train_generator.class_indices)\n",
    "\n",
    "# Calcular pesos das classes para balanceamento\n",
    "labels = np.array([train_generator.classes])\n",
    "class_weights = compute_class_weight(\"balanced\", classes=np.unique(labels), y=labels.flatten())\n",
    "class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "# Carrega o MobileNetV2 pré-treinado\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "base_model.trainable = False  # Inicialmente mantém congelado\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)  # Normalização para evitar sobreajuste\n",
    "x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "x = Dropout(0.5)(x)  # Mantendo dropout adequado para melhor regularização\n",
    "x = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "x = Dropout(0.4)(x)\n",
    "predictions = Dense(len(classes), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinamento inicial\n",
    "epochs = 15\n",
    "if val_generator.samples == 0:\n",
    "    print(\"Nenhuma imagem para validação. Treinando sem validação.\")\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=epochs,\n",
    "        class_weight=class_weight_dict\n",
    "    )\n",
    "else:\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=epochs,\n",
    "        class_weight=class_weight_dict\n",
    "    )\n",
    "\n",
    "# Ajuste fino liberando mais camadas do modelo\n",
    "for layer in base_model.layers[-80:]:  # Liberando mais camadas para aprendizado\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompilar o modelo com taxa de aprendizado menor\n",
    "model.compile(optimizer=Adam(learning_rate=1e-6), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinar novamente por mais 5 épocas (ajuste fino)\n",
    "history_finetune = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=5,\n",
    "    class_weight=class_weight_dict\n",
    ")\n",
    "\n",
    "model.save(\"face_recognition_model.h5\")\n",
    "\n",
    "print(\"Modelo treinado e salvo com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "5BGH3mb6InK0",
    "outputId": "ea946b3d-2387-4644-8baf-ae04a6911e25"
   },
   "outputs": [],
   "source": [
    "# Exibir precisão e perda do modelo\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "# Gráfico da acurácia\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='Treino')\n",
    "plt.plot(history.history['val_accuracy'], label='Validação')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.legend()\n",
    "plt.title('Evolução da Acurácia')\n",
    "\n",
    "# Gráfico da perda\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='Treino')\n",
    "plt.plot(history.history['val_loss'], label='Validação')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Perda')\n",
    "plt.legend()\n",
    "plt.title('Evolução da Perda')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MsmzHx8-MRXv"
   },
   "source": [
    "# 5. Detecção de Rostos na Imagem de Teste e Classificação de rosto\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "id": "3L5r1bdQLX0o",
    "outputId": "ae7d1ddb-b009-4a17-86d1-2def09ffd96f"
   },
   "outputs": [],
   "source": [
    "# Carrega o modelo treinado\n",
    "model = tf.keras.models.load_model(\"face_recognition_model.h5\")\n",
    "\n",
    "# Lista de classes, na mesma ordem do treinamento:\n",
    "class_labels = [\"marina\", \"tadeu\"]\n",
    "\n",
    "# Parâmetros de pré-processamento (tamanho esperado pelo modelo)\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "# Carrega a imagem original para desenhar os rótulos\n",
    "img_original = cv2.imread('capture.jpg')\n",
    "if img_original is None:\n",
    "    raise ValueError(\"Imagem 'capture.jpg' não encontrada!\")\n",
    "\n",
    "for ((x, y, w, h), face_img) in face_regions:\n",
    "    # Redimensiona a face para o tamanho esperado pelo modelo\n",
    "    face_resized = cv2.resize(face_img, IMG_SIZE)\n",
    "    # Normaliza a imagem (0 a 1)\n",
    "    face_resized = face_resized.astype(\"float32\") / 255.0\n",
    "    # Adiciona dimensão de batch\n",
    "    face_input = np.expand_dims(face_resized, axis=0)\n",
    "\n",
    "    # Faz a predição\n",
    "    preds = model.predict(face_input)\n",
    "    class_id = int(np.argmax(preds))\n",
    "    confidence = float(np.max(preds))\n",
    "\n",
    "    # Verifica se o índice predito está dentro do intervalo esperado\n",
    "    if class_id < len(class_labels):\n",
    "        name = class_labels[class_id]\n",
    "    else:\n",
    "        name = \"Desconhecido\"\n",
    "\n",
    "    confidence_percent = confidence * 100\n",
    "\n",
    "    # Cria o label de texto\n",
    "    label = f\"{name} ({confidence_percent:.2f}%)\"\n",
    "\n",
    "    # Calcula o tamanho do texto para desenhar um fundo\n",
    "    font_scale = 0.8\n",
    "    thickness = 2\n",
    "    (text_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)\n",
    "\n",
    "    # Define coordenadas para o retângulo de fundo do label\n",
    "    # Ajusta a posição para que o fundo fique acima do bounding box, sem sair da imagem\n",
    "    label_x = x\n",
    "    label_y = y - 10 if y - 10 > text_height + baseline else y + text_height + baseline + 10\n",
    "\n",
    "    # Desenha o retângulo preenchido como fundo (cor verde, mas pode ajustar)\n",
    "    cv2.rectangle(img_original, (label_x, label_y - text_height - baseline), (label_x + text_width, label_y), (0, 255, 0), cv2.FILLED)\n",
    "\n",
    "    # Escreve o texto em cima do retângulo, com cor preta\n",
    "    cv2.putText(img_original, label, (label_x, label_y - baseline), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 0), thickness)\n",
    "\n",
    "    # Desenha o bounding box da face\n",
    "    cv2.rectangle(img_original, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "# Exibe a imagem final com labels aprimorados\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(cv2.cvtColor(img_original, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
